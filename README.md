# WRO-2025-Future-Engineers

Official repository of Team Los Grises Superiores for the Future Engineers – World Robot Olympiad 2025.
<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/b3e384a1-e19b-4c7f-addf-655aeb32bc3a" />

---

## Contents

* [Mobility Management](#mobility-management)

  * [Chassis](#chassis)  
    - Image 1.1: Chassis photo
  * [Steering System](#steering-system)  
    - Image 1.2: Steering system photo  
    - Image 2.1: Set 1  
    - Image 2.2: Render front part
  * [Movement and Traction System](#movement-and-traction-system)  
    - Image 3.1: Set 2  
    - Image 3.2: Render back part
  * [Differential](#differential)  
    - Image 4.1: Differential example

* [Power and Sense Management](#power-and-sense-management)

  * [Power Management](#power-management)  
    - Image 5.1: Power and Sense Diagram  
    - Image 5.2: EV3 Brick  
    - Image 5.3: Medium Motor Voltage
  * [Sense Management](#sense-management)  
    - Image 5.4: Camera Information  
    - Image 5.5: PCB Design

* [Obstacle Management](#obstacle-management)

* [Manual Direction PDF](#manual-direction-pdf)  
* [Differential Manual PDF](#differential-manual-pdf)  
* [Hardware Developer Kit PDF](#hardware-developer-kit-pdf)

---


## Mobility Management

### Chassis

We built our vehicle using LEGO pieces, chosen for their accessibility and for allowing a compact and efficient design, which ensures good performance on the track. Initially, we designed the prototype using Studio 2.0 software to identify the most suitable LEGO parts for the chassis. Then, we evaluated different steering system methods and adapted them to our custom chassis, paying close attention to the required measurements and proportions.

<div align="center">
  <img width="500" height="500" alt="Chassis" src="https://github.com/user-attachments/assets/f0f2ec53-35a1-495b-a551-b19bc37c49a3" />
  <p><em>Image 1.1: Chassis photo</em></p>
</div>

---

### Steering System

For the steering system, we opted for the medium motor from the EV3 Core Set. The gear mechanism converts and transmits the motor’s rotation into steering movement, with a maximum steering angle of 45°. On the steering motor, a 12-tooth double bevel gear transmits motion to a 12-tooth single gear, which, through a proportional shaft, transfers the movement generated by the motor to the wheels. Additionally, the wheels are connected through a linkage bar that ensures both rotate simultaneously and in a coordinated manner, providing precise control during turns and track navigation.

<div align="center">
  <img width="300" height="300" alt="Steering system" src="https://github.com/user-attachments/assets/813a3d07-1033-4852-a699-a6eef89279d8" />
  <p><em>Image 1.2: Steering system photo</em></p>
</div>

<div align="center">
  <img width="300" height="300" alt="Set 1" src="https://github.com/user-attachments/assets/46e202f6-aba2-4c50-96f0-182f83e499fe" />
  <p><em>Image 2.1: Set 1</em></p>
</div>

<div align="center">
  <img width="300" height="300" alt="Render front part" src="https://github.com/user-attachments/assets/f3185aaf-427e-4545-b5fc-99059a3537b4" />
  <p><em>Image 2.2: Render front part</em></p>
</div>

[Manual Direction PDF](https://github.com/user-attachments/files/22270572/manual.direction.pdf)

---

### Movement and Traction System

We also designed the movement and traction system that will drive our vehicle. Initially, we considered using a single LEGO medium motor with a differential system to power both wheels; however, this motor did not provide enough power. To achieve more efficient movement, a second medium motor was added to the differential system, along with a transmission that converts the motor’s energy into mechanical energy for the wheels.

Using medium motors provides fast and precise movements, with a position accuracy of ±1°, a torque of 0.08 Nm, and a no-load speed of 240 RPM.

The transmission consists of 20-tooth gears directly connected to 12-tooth gears. This setup increases the rotational speed delivered to the differential, which then transmits the motion through shafts to a 28-tooth gear, subsequently connected to a 20-tooth gear that drives the wheels on both sides of the vehicle.

<div align="center">
  <img width="300" height="300" alt="Set 2" src="https://github.com/user-attachments/assets/6d06e1fc-8637-4078-b9ca-1b4b27277880" />
  <p><em>Image 3.1: Set 2</em></p>
</div>

<div align="center">
  <img width="300" height="300" alt="Render back part" src="https://github.com/user-attachments/assets/992c28f3-348e-4574-af18-7d5bda827877" />
  <p><em>Image 3.2: Render back part</em></p>
</div>
[Differential Manual PDF](https://github.com/user-attachments/files/22326888/Diferencial.manual.pdf)

---

### Differential

**What is a differential?**

It is a mechanical component located on the drive axle of a vehicle.

**Operating principle:**
The differential is responsible for distributing engine torque to the wheels.

* **Power input:** The motor transmits torque to the pinion and crown (bevel gear) of the differential.
* **Torque distribution:** Inside the differential, planetary or satellite gears allow:

  * When the vehicle moves straight: both wheels rotate at the same speed.
  * When the vehicle turns: the outer wheel rotates faster than the inner wheel.
* **Power output:** Each axle connected to the wheels receives the appropriate torque.

<div align="center">
  <img width="500" height="400" alt="Differential example" src="https://github.com/user-attachments/assets/841f8551-b8cd-43e2-a964-24c97eb4f7ce" />
  <p><em>Image 4.1: Differential example</em></p>
</div>



---

## Power and Sense Management

<img width="825" height="237" alt="Power and Sense Diagram" src="https://github.com/user-attachments/assets/9167d4d9-a9f3-4ca6-bf3f-da7acba2cc4e" />
<p><em>Image 5.1: Power and Sense Diagram</em></p>

### Power Management

Our main controller is the EV3 Brick from LEGO Mindstorms. This device receives information from the sensors and is responsible for controlling the motors. The controller features 4 motor ports (A, B, C, D) and 4 sensor ports (1, 2, 3, 4).

It is powered by a rechargeable lithium battery with an output of 10 V and 2050 mAh capacity. We consulted the hardware manual to understand the power consumption specifications of both motors and sensors, in order to optimize battery performance and select the most suitable sensors for our car.

Our robot uses three EV3 Medium Motors:

* **Two motors for movement:** Each connected to a transmission system and a differential, providing efficient power distribution to the wheels. These motors typically consume **150–250 mA**.
* **One motor for steering:** This motor generally operates under a lighter load, consuming **120–250 mA**.

<div align="center">
  <img width="406" height="297" alt="EV3 Brick" src="https://github.com/user-attachments/assets/35571866-e5ca-4a87-aad3-f22cd2aee42c" />
  <p><em>Image 5.2: EV3 Brick</em></p>
</div>

<div align="center">
  <img width="326" height="96" alt="Medium Motor Voltage" src="https://github.com/user-attachments/assets/ea92cc7c-aa1b-4ce5-b05f-c80b4cd0d48a" />
  <p><em>Image 5.3: Medium Motor Voltage</em></p>
</div>

[Hardware Developer Kit PDF](https://github.com/user-attachments/files/22328277/hardware_developer_kit.pdf)

### Sense Management

For the sensor system, we used two OpenMV H7 cameras: one is responsible for avoiding collisions with walls, while the other detects traffic lights, counts lines, and locates the parking area. We also calculated the cameras’ positions on the vehicle to ensure correct vision using wide-angle lenses. We selected these cameras due to their low power consumption, which does not affect the EV3, and their compact size, making them easy to integrate into the chassis. Each camera draws up to 480 mA at 3.3 V. To connect them to the EV3, we designed a PCB in EasyEDA that enables communication through the RX, TX, Vin, and GND ports. The cameras also include their own IDE for programming in Python.

<div align="center">
  <img width="452" height="567" alt="Camera Information" src="https://github.com/user-attachments/assets/e2bb0995-a4e0-47b4-b147-fb7336de7c5f" />
  <p><em>Image 5.4: Camera Information</em></p>
</div>






<div align="center">
  <img width="400" height="300" alt="PCB Design" src="https://github.com/user-attachments/assets/7615369a-8065-4bf4-945b-35ec4d5ec838" />
  <p><em>Image 5.5: PCB Design</em></p>
</div>

## Obstacle management

## Vision System

The vision system is one of the fundamental components of the robot, as it enables real-time interpretation of the competition environment and decision-making. For this purpose, an OpenMV camera was employed, configured and optimized during different stages of the project.

The development included color calibration processes, definition and evolution of Regions of Interest (ROIs), and the design of strategies for obstacle detection and collision prevention.
The system detects key colors (white, red, green, blue, and orange) through LAB calibration, using four ROIs (low, middle, high, and black) for line tracking, corridor width regulation, obstacle detection, and collision alerts.

The X position of the blobs determines the avoidance maneuver according to the competition rules:

Red = turn right

Green = turn left

## Calibration

During the first tests, instabilities in color identification were detected due to variations in ambient light.
To solve this, camera parameters such as auto-gain, auto-white balance, and exposure were fixed, ensuring more stable detection.

Additionally, a progressive adjustment of LAB thresholds was performed for the key track colors (white, red, green, blue, orange). This process allowed the system to operate more consistently under different lighting conditions.

##  ROI Evolution

Initial stage: A central dynamic ROI anchored to the white floor was used, focused on following the main line.

Improvement proposal: Trapezoidal ROIs were considered to cover both the path and pillars.

September: A system of three horizontal ROIs (low, middle, high) was incorporated, initially fixed and later transformed into dynamic ones, always anchored to the white floor. These allowed better detection of wide/narrow corridors and provided support on curves.

Additional ROI: A black ROI was introduced to specifically alert collisions, replacing direct pillar detection in critical cases.

Currently, the robot uses four main ROIs:

Low ROI: Line tracking and detection of floor-level colors.

Middle ROI: Detection of intermediate obstacles (red, green, orange).

High ROI: Support in curves and far obstacle detection.

Black ROI: Collision alerts in case of dark-area detection.

## Detection and Avoidance Strategies

The vision system was also designed to support obstacle avoidance logic.
The X coordinate at the base of the blob was chosen as the main metric, as it proved more reliable than the object area, which sometimes produced inconsistent data.

Additionally, the EV3 logic uses competition rules to define maneuvers:

Red pillar = turn right

Green pillar = turn left

| Identified Problem                                             | Implemented Solution                                                                                           |
| -------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| Light variations caused unstable detections.                   | Fixed **auto-gain**, **auto-white balance**, and **exposure** parameters in OpenMV, ensuring stable detection. |
| In curves, the robot lost sight of far pillars.                | Added a compensation strategy with blob base position and extended dynamic ROIs.                               |
| The robot detected oversized blobs, generating confusing data. | Adopted **X coordinate at blob base** as the main metric; area kept only as secondary reference.               |
| OpenMV scripts were redundant, complicating EV3 integration.   | Unified data transmission in **LPF2 slots**, removing redundancies like `PRINT_EVERY` and `SEND_EVERY`.        |
| Line follower was not reactive to corridor width changes.      | Incorporated corridor width as a proportional correction variable (**KP adjustment in EV3**).                  |
| Risk of collision when pillars were not properly detected.     | Replaced pillar ROI with a **black ROI**, dedicated to collision alerts.                                       |

Line Tracking

To improve response, a dynamic horizontal ROI scheme was added, allowing the identification of the relative line position at different image heights.

The position error is translated into a proportional signal inside the EV3, where the initial KP = 1, later tuned for better sensitivity in both curves and straights.

Corridor Width Regulation

One of the key improvements was the use of corridor width as a control metric.

From the OpenMV data (width detected in lower ROIs), a proportional calculation was integrated inside the EV3 controller. This allowed the robot to adjust its trajectory based on available free space, achieving more adaptive navigation.

Obstacle Avoidance

The obstacle avoidance logic followed competition rules:

Red pillar = right turn

Green pillar = left turn

The maneuver side was determined by the difference between the X position detected by the camera and a predefined X target, ensuring reliable decision-making.

Data Communication (OpenMV → EV3)

Communication between OpenMV and EV3 is done via the LPF2 protocol.
Data transmission was simplified by unifying metrics into specific slots and removing redundant functions such as PRINT_EVERY and SEND_EVERY.

| Sensor / Source      | Extracted Metric                                            | Usage in Control System                            |
| -------------------- | ----------------------------------------------------------- | -------------------------------------------------- |
| OpenMV – Low ROI     | Line error (relative floor position)                        | Main trajectory tracking                           |
| OpenMV – Middle ROI  | Corridor width and intermediate colors (red, green, orange) | Proportional regulation & obstacle anticipation    |
| OpenMV – High ROI    | Far obstacle position                                       | Curve support & avoidance preparation              |
| OpenMV – Black ROI   | Dark areas detection                                        | Collision alert (binary indicator sent to EV3)     |
| OpenMV – Color Blobs | X coordinate at object base Y                               | Defines avoidance side (Red = right, Green = left) |
| EV3 – Motor Encoders | Speed and distance traveled                                 | Smooth speed and maneuver control                  |
| EV3 – Internal Logic | Proportional variable (KP)                                  | Dynamic correction in curves and straights         |




